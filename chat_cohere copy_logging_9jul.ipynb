{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%pip install -U langchain-cohere\\n%pip install langchain-huggingface\\n%pip install datasets\\n%pip install transformers huggingface_hub sentence\\n%pip install -U sentence-transformers\\n%pip install sentencepiece\\n%pip install \"transformers[sentencepiece]\"\\n\\n%pip install pdf2image pytesseract'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%pip install -U langchain-cohere\n",
    "%pip install langchain-huggingface\n",
    "%pip install datasets\n",
    "%pip install transformers huggingface_hub sentence\n",
    "%pip install -U sentence-transformers\n",
    "%pip install sentencepiece\n",
    "%pip install \"transformers[sentencepiece]\"\n",
    "\n",
    "%pip install pdf2image pytesseract'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "log_dir = \"data/logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)  # Create logs directory if it doesn't exist\n",
    "log_file = os.path.join(log_dir, f\"hmr_generator_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file),  # Write logs to file\n",
    "        logging.StreamHandler()         # Print logs to console\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to MPS (Apple Silicon)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Device set to MPS (Apple Silicon)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Device set to CUDA (NVIDIA GPU)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Device set to CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from transformers import AutoTokenizer, AutoModel\\nimport torch\\nimport torch.nn.functional as F\\nfrom langchain.document_loaders import TextLoader\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\n\\nmodel_name_sent = \"sentence-transformers/all-MiniLM-L6-v2\"\\ntokenizer = AutoTokenizer.from_pretrained(model_name_sent)\\nmodel = AutoModel.from_pretrained(model_name_sent)\\n\\n#Mean Pooling - Take attention mask into account for correct averaging\\ndef mean_pooling(model_output, attention_mask):\\n    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\\n    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\\n\\n\\n# Sentences we want sentence embeddings for\\nsentences = [\\'This is an example sentence\\', \\'Each sentence is converted\\']\\n\\n# Tokenize sentences\\nencoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors=\\'pt\\')\\n\\n# Compute token embeddings\\nwith torch.no_grad():\\n    model_output = model(**encoded_input)\\n\\n# Perform pooling\\nsentence_embeddings = mean_pooling(model_output, encoded_input[\\'attention_mask\\'])\\n\\n# Normalize embeddings\\nsentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\\n\\nprint(\"Sentence embeddings:\")\\nprint(sentence_embeddings)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#works but dont use now temporary disabled\n",
    "\n",
    "\n",
    "# # Load model directly\n",
    "'''from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "model_name_sent = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_sent)\n",
    "model = AutoModel.from_pretrained(model_name_sent)\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#test################BS\\n\\nfrom langchain.document_loaders import UnstructuredFileLoader\\nfrom pathlib import Path\\n\\ndef load_all_docs(*folder_paths):\\n    docs = []\\n    for folder_path in folder_paths:\\n        files = list(Path(folder_path).glob(\"*\"))\\n        for file in files:\\n            loader = UnstructuredFileLoader(str(file))\\n            docs.extend(loader.load())\\n        return docs\\n\\ndocuments = load_all_docs(\"data/pdf/\",\"data/text/\")'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#test################BS\n",
    "\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from pathlib import Path\n",
    "\n",
    "def load_all_docs(*folder_paths):\n",
    "    docs = []\n",
    "    for folder_path in folder_paths:\n",
    "        files = list(Path(folder_path).glob(\"*\"))\n",
    "        for file in files:\n",
    "            loader = UnstructuredFileLoader(str(file))\n",
    "            docs.extend(loader.load())\n",
    "        return docs\n",
    "\n",
    "documents = load_all_docs(\"data/pdf/\",\"data/text/\")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from PyPDF2 import PdfReader\\n\\nreader = PdfReader(\"data/pdf/esbc-configuration-guide.pdf\")\\nfor i, page in enumerate(reader.pages):\\n    try:\\n        text = page.extract_text()\\n        print(f\"Page {i} extracted successfully\")\\n    except Exception as e:\\n        print(f\"Page {i} failed: {e}\")'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check which file is coorupted\n",
    "# \n",
    "'''from PyPDF2 import PdfReader\n",
    "\n",
    "reader = PdfReader(\"data/pdf/esbc-configuration-guide.pdf\")\n",
    "for i, page in enumerate(reader.pages):\n",
    "    try:\n",
    "        text = page.extract_text()\n",
    "        print(f\"Page {i} extracted successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Page {i} failed: {e}\")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]2025-07-10 02:06:18,118 [DEBUG] Processing file: data/text/sfbuksbu_Chris.rtf\n",
      "2025-07-10 02:06:18,119 [DEBUG] Processing file: data/text/store values from REFER and use in INVITE.txt\n",
      "2025-07-10 02:06:18,120 [DEBUG] Processing file: data/text/run-1.rtf\n",
      "2025-07-10 02:06:18,120 [DEBUG] Processing file: data/text/1800flowers modify request and to host.txt\n",
      "2025-07-10 02:06:18,121 [DEBUG] Processing file: data/text/stripSDP18x.txt\n",
      "2025-07-10 02:06:18,121 [DEBUG] Processing file: data/text/reject REFER.txt\n",
      "2025-07-10 02:06:18,122 [DEBUG] Processing file: data/text/SBCPH4_Chris.rtf\n",
      "2025-07-10 02:06:18,122 [DEBUG] Processing file: data/text/modify to and from user with large to user number.txt\n",
      "2025-07-10 02:06:18,123 [DEBUG] Processing file: data/text/HMR to add a cn RURI param containing charge number.rtf\n",
      "2025-07-10 02:06:18,123 [DEBUG] Processing file: data/text/run-2-MoW.rtf\n",
      "2025-07-10 02:06:18,124 [DEBUG] Processing file: data/text/change From Host and Remote-Party-ID Host if Diversion is Presenting.txt\n",
      "2025-07-10 02:06:18,124 [DEBUG] Processing file: data/text/hmr modify request uri.txt\n",
      "2025-07-10 02:06:18,125 [DEBUG] Processing file: data/text/GBWD402IB201_Chris.rtf\n",
      "2025-07-10 02:06:18,125 [DEBUG] Processing file: data/text/hmr examples.txt\n",
      "2025-07-10 02:06:18,126 [DEBUG] Processing file: data/text/extractXdirnuminToMetadata.txt\n",
      "2025-07-10 02:06:18,126 [DEBUG] Processing file: data/text/removeXdirnumfromSDP.txt\n",
      "2025-07-10 02:06:18,127 [DEBUG] Processing file: data/text/Modify request-uri.txt\n",
      "2025-07-10 02:06:18,127 [DEBUG] Processing file: data/text/sip-manipulation test.txt\n",
      "2025-07-10 02:06:18,127 [DEBUG] Processing file: data/text/HMR to fix user portion of RURI with user portion of To.rtf\n",
      "2025-07-10 02:06:18,128 [DEBUG] Processing file: data/text/HMR to create Diversion when To is not 911 or 9911.rtf\n",
      "2025-07-10 02:06:18,128 [DEBUG] Processing file: data/text/two diversion headers check for user busy - boolean.txt\n",
      "2025-07-10 02:06:18,129 [DEBUG] Processing file: data/text/check for history-info parameter and modify max-forwrads.txt\n",
      "2025-07-10 02:06:18,129 [DEBUG] Processing file: data/text/delete uri-user-parameter named Csel from request-uri and to-uri.txt\n",
      "2025-07-10 02:06:18,130 [DEBUG] Processing file: data/text/Working Copy of p asserted identity - from user.txt\n",
      "2025-07-10 02:06:18,130 [DEBUG] Processing file: data/text/SBC Allows INVITE When ‘from’ Header Is Outside DDI Range.rtf\n",
      "2025-07-10 02:06:18,131 [DEBUG] Processing file: data/text/Modify Refer-To with to-uri host after from-uri boolean check.txt\n",
      "2025-07-10 02:06:18,131 [DEBUG] Processing file: data/text/OPTIONS reject and respond with 200 OK.txt\n",
      "2025-07-10 02:06:18,131 [DEBUG] Processing file: data/text/HMR to modify RN.rtf\n",
      "2025-07-10 02:06:18,132 [DEBUG] Processing file: data/text/HMR to update From with PAI info if Referred-By header exists.rtf\n",
      "2025-07-10 02:06:18,132 [DEBUG] Processing file: data/text/HMR to delete one Header and keep the other Headers which exist in multiples in a SIP message.rtf\n",
      "2025-07-10 02:06:18,133 [DEBUG] Processing file: data/text/HMR to add call=orig if P-Served-User has sescase=orig.rtf\n",
      "2025-07-10 02:06:18,133 [DEBUG] Processing file: data/text/Untitled_TEAMS.rtf\n",
      "2025-07-10 02:06:18,134 [DEBUG] Processing file: data/text/insert from user into p-asserted-identity user field.txt\n",
      "2025-07-10 02:06:18,134 [DEBUG] Processing file: data/text/NATSDP.rtf\n",
      "2025-07-10 02:06:18,135 [DEBUG] Processing file: data/text/SBC Failed To Forward RTP To SRTP Leg with Near-side NAT.rtf\n",
      "2025-07-10 02:06:18,135 [DEBUG] Processing file: data/text/488to415.txt\n",
      "2025-07-10 02:06:18,135 [DEBUG] Processing file: data/text/ow to Remove P-Asserted-Identity (PAI) from Responses - pai-strip and:or HMR.rtf\n",
      "2025-07-10 02:06:18,136 [DEBUG] Processing file: data/text/run-1-hmr-MA.rtf\n",
      "2025-07-10 02:06:18,136 [DEBUG] Processing file: data/text/HMR_Add_Update_Diversion_Based_on_TO_User-Uri.txt\n",
      "2025-07-10 02:06:18,136 [DEBUG] Processing file: data/text/hmr-tsbc-99.rtf\n",
      "2025-07-10 02:06:18,137 [DEBUG] Processing file: data/text/dns cache and lookup.txt\n",
      "2025-07-10 02:06:18,137 [DEBUG] Processing file: data/text/HMR to convert SDP payload of 96 to 101.rtf\n",
      "2025-07-10 02:06:18,138 [DEBUG] Processing file: data/text/hmr-tsbc-98.rtf\n",
      "2025-07-10 02:06:18,138 [DEBUG] Processing file: data/text/delete sdp attributes.txt\n",
      "2025-07-10 02:06:18,139 [DEBUG] Processing file: data/text/p asserted identity - from user.txt\n",
      "2025-07-10 02:06:18,139 [DEBUG] Processing file: data/text/Store INFO request-uri params, create temp header and use for outbound request uri.txt\n",
      "2025-07-10 02:06:18,140 [DEBUG] Processing file: data/text/AgentIDHMR.txt\n",
      "2025-07-10 02:06:18,140 [DEBUG] Processing file: data/text/SBC_VOLTE_HMR.rtf\n",
      "2025-07-10 02:06:18,141 [DEBUG] Processing file: data/text/modify ptime from 30 to 20.txt\n",
      "2025-07-10 02:06:18,141 [DEBUG] Processing file: data/text/HMR 302 Abbvie.rtf\n",
      "2025-07-10 02:06:18,142 [DEBUG] Processing file: data/text/HMR to update FMTP entries in SDP for Bria clients.rtf\n",
      "2025-07-10 02:06:18,142 [DEBUG] Processing file: data/text/store to tag, boolean check to swap PAI and from users - used for reinvite.txt\n",
      "2025-07-10 02:06:18,143 [DEBUG] Processing file: data/text/mime-rule.rtf\n",
      "2025-07-10 02:06:18,143 [DEBUG] Processing file: data/text/UPDATE Method Is Missing From Allow Header Of The 200 OK Response.rtf\n",
      "2025-07-10 02:06:18,143 [DEBUG] Processing file: data/text/stripSDPHMR_from_183.txt\n",
      "2025-07-10 02:06:18,144 [DEBUG] Processing file: data/text/hmr test.txt\n",
      "2025-07-10 02:06:18,144 [DEBUG] Processing file: data/text/modify sdp sendrecv to sendonly.txt\n",
      "2025-07-10 02:06:18,144 [DEBUG] Processing file: data/text/ to remove DTG from the RURI header.rtf\n",
      "2025-07-10 02:06:18,145 [DEBUG] Processing file: data/text/invokeXdirnumoutToMetadataTranslation.txt\n",
      "2025-07-10 02:06:18,145 [DEBUG] Processing file: data/text/HMR to add (PAI) P-Asserted-Identity.rtf\n",
      "2025-07-10 02:06:18,146 [DEBUG] Processing file: data/text/remove G729 codec.txt\n",
      "2025-07-10 02:06:18,146 [DEBUG] Processing file: data/text/hmr-tsbc-mnch_1.rtf\n",
      "2025-07-10 02:06:18,146 [DEBUG] Processing file: data/text/hmr-solution-final3.txt\n",
      "2025-07-10 02:06:18,147 [DEBUG] Processing file: data/text/two diversion testing.txt\n",
      "2025-07-10 02:06:18,147 [DEBUG] Processing file: data/text/block Anonymous caller to specific number.rtf\n",
      "2025-07-10 02:06:18,148 [DEBUG] Processing file: data/text/HMRs.rtf\n",
      "2025-07-10 02:06:18,148 [DEBUG] Processing file: data/text/Chris_680SBCtA04A.rtf\n",
      "2025-07-10 02:06:18,148 [DEBUG] Processing file: data/text/block friendly scanner.txt\n",
      "2025-07-10 02:06:18,149 [DEBUG] Processing file: data/text/store from user and create from display with that user.txt\n",
      "2025-07-10 02:06:18,149 [DEBUG] Processing file: data/text/STPUAT_Chris.rtf\n",
      "2025-07-10 02:06:18,150 [DEBUG] Processing file: data/text/HMR-tsbc-89.rtf\n",
      "2025-07-10 02:06:18,150 [DEBUG] Processing file: data/text/HMR-move-M-linesinSDP.txt\n",
      "2025-07-10 02:06:18,150 [DEBUG] Processing file: data/text/hmr-tsbc-90.rtf\n",
      "2025-07-10 02:06:18,151 [DEBUG] Processing file: data/text/Replace 603 status line with 486 after performing boolean check on 486 AND to-users.txt\n",
      "2025-07-10 02:06:18,151 [DEBUG] Processing file: data/text/rachid's hmrs.txt\n",
      "2025-07-10 02:06:18,152 [DEBUG] Processing file: data/text/Allow only one user-agent to register.txt\n",
      "2025-07-10 02:06:18,152 [DEBUG] Processing file: data/text/hmr-tsbc-91.rtf\n",
      "2025-07-10 02:06:18,153 [DEBUG] Processing file: data/text/addMLineHMR.txt\n",
      "2025-07-10 02:06:18,153 [DEBUG] Processing file: data/text/invokeXdirnuminToMetadataTranslation.txt\n",
      "2025-07-10 02:06:18,155 [DEBUG] Processing file: data/text/check for contact and PAI usre - add if not present.txt\n",
      "2025-07-10 02:06:18,157 [DEBUG] Processing file: data/text/HMR's.rtf\n",
      "2025-07-10 02:06:18,158 [DEBUG] Processing file: data/text/6300 OPTIONS respond locally.txt\n",
      "2025-07-10 02:06:18,159 [DEBUG] Processing file: data/text/hmr-tsbc-93.rtf\n",
      "2025-07-10 02:06:18,161 [DEBUG] Processing file: data/text/sip_manipulation_chg_ruri.txt\n",
      "2025-07-10 02:06:18,162 [DEBUG] Processing file: data/text/storeXdirnuminInSDP.txt\n",
      "2025-07-10 02:06:18,163 [DEBUG] Processing file: data/text/Alan_pkg_HMR.rtf\n",
      "2025-07-10 02:06:18,164 [DEBUG] Processing file: data/text/remove UPDATE.txt\n",
      "2025-07-10 02:06:18,165 [DEBUG] Processing file: data/text/hmr-tsbc-96.rtf\n",
      "2025-07-10 02:06:18,166 [DEBUG] Processing file: data/text/remove second m line.txt\n",
      "2025-07-10 02:06:18,168 [DEBUG] Processing file: data/text/hmr-tsbc-97.rtf\n",
      "2025-07-10 02:06:18,169 [DEBUG] Processing file: data/text/RFC3711_RFC5939_HMRs_AvayaClient_OCSBC.txt\n",
      "2025-07-10 02:06:18,169 [DEBUG] Processing file: data/text/boolean check - add diversion if header exists.txt\n",
      "2025-07-10 02:06:18,169 [DEBUG] Processing file: data/text/Check from header for anonymous and modify from host to anonymous.invalid if present.txt\n",
      "2025-07-10 02:06:18,170 [DEBUG] Processing file: data/text/hrm add +1 for natl and intl calls - remove 00.txt\n",
      "2025-07-10 02:06:18,170 [DEBUG] Processing file: data/text/modify host from server to match local-policy (sbc ip address).txt\n",
      "2025-07-10 02:06:18,171 [DEBUG] Processing file: data/text/check boolean for PAI header and add History-Info.txt\n",
      "2025-07-10 02:06:18,171 [DEBUG] Processing file: data/text/AcmePacket_SBC_Call_Blocking_Configuration_Using_Sip_manipulation_July-2013.txt\n",
      "2025-07-10 02:06:18,171 [DEBUG] Processing file: data/text/hmr_remove plus 1.txt\n",
      "2025-07-10 02:06:18,172 [DEBUG] Processing file: data/text/SBCMS01-6300_Chris.rtf\n",
      "2025-07-10 02:06:18,173 [DEBUG] Processing file: data/text/Miguel_Codec_nego.rtf\n",
      "2025-07-10 02:06:18,174 [DEBUG] Processing file: data/text/modify_anonymous.txt\n",
      "2025-07-10 02:06:18,175 [DEBUG] Processing file: data/text/store from and to user and create from and to display with that user.txt\n",
      "2025-07-10 02:06:18,176 [DEBUG] Processing file: data/text/2257253.1_Vernal.rtf\n",
      "2025-07-10 02:06:18,177 [DEBUG] Processing file: data/text/Oracle SBC- HMR to Modify the telephone-event payload to 101.rtf\n",
      "2025-07-10 02:06:18,177 [DEBUG] Processing file: data/text/remove sdp line.txt\n",
      "2025-07-10 02:06:18,177 [DEBUG] Processing file: data/text/Chris_run_config1.rtf\n",
      "2025-07-10 02:06:18,178 [DEBUG] Processing file: data/text/modify contact of replies to invite.txt\n",
      "2025-07-10 02:06:18,178 [DEBUG] Processing file: data/text/Modify_anonymous_from_and_then_perform_boolean_check_-_if_anon,_remove_G729_from_SDP.txt\n",
      "2025-07-10 02:06:18,178 [DEBUG] Processing file: data/text/hmr check from and add diversion.txt\n",
      "2025-07-10 02:06:18,179 [DEBUG] Processing file: data/text/add q850 cause code.txt\n",
      "2025-07-10 02:06:18,179 [DEBUG] Processing file: data/text/Modify Refer-To with request-uri host after from-uri boolean check.txt\n",
      "2025-07-10 02:06:18,180 [DEBUG] Processing file: data/text/add refresher to session expires.txt\n",
      "2025-07-10 02:06:18,180 [DEBUG] Processing file: data/text/sips2sip-hmr.txt\n",
      "2025-07-10 02:06:18,180 [DEBUG] Processing file: data/text/storeXdirnumoutInSDP.txt\n",
      "2025-07-10 02:06:18,181 [DEBUG] Processing file: data/text/VF_Portugal.rtf\n",
      "2025-07-10 02:06:18,181 [DEBUG] Processing file: data/text/remove t38 information.txt\n",
      "2025-07-10 02:06:18,181 [DEBUG] Processing file: data/text/HMR-Div-RURI-From.txt\n",
      "2025-07-10 02:06:18,182 [DEBUG] Processing file: data/text/mod refer-to header with next hop ip after boolean check.txt\n",
      "2025-07-10 02:06:18,182 [DEBUG] Processing file: data/text/Modify to user while matching prefix.txt\n",
      "2025-07-10 02:06:18,182 [DEBUG] Processing file: data/text/strip UPDATE and enforcement-profile.txt\n",
      "2025-07-10 02:06:18,183 [DEBUG] Processing file: data/text/extractXdirnumoutToMetadata.txt\n",
      "2025-07-10 02:06:18,183 [DEBUG] Processing file: data/text/hmr add +1.txt\n",
      "2025-07-10 02:06:18,183 [DEBUG] Processing file: data/text/2541274.1-Vernal.rtfd/TXT.rtf\n",
      "2025-07-10 02:06:18,184 [DEBUG] Processing file: data/text/2393502.1-Vernal.rtfd/TXT.rtf\n",
      " 99%|█████████▉| 124/125 [00:00<00:00, 1867.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'documents = pdf + text\\nprint(\"Total number of documents: \", len(documents))\\n#documents'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Documents\n",
    "from langchain.document_loaders import PyPDFLoader,PyPDFDirectoryLoader,DirectoryLoader,TextLoader\n",
    "\n",
    "#dont use pdf part as it will have image,Please use only text pdf \n",
    "'''loader_pdf = DirectoryLoader(\"data/pdf/\" , glob= '**/*.pdf' , show_progress=True ,loader_cls=PyPDFLoader)\n",
    "loader_pdf\n",
    "pdf = loader_pdf.load()\n",
    "len(pdf)'''\n",
    "\n",
    "loader_text = DirectoryLoader(\"data/text/\" , glob= '**/*' , show_progress=True ,loader_cls=TextLoader)\n",
    "loader_text\n",
    "text = loader_text.load()\n",
    "len(text)\n",
    "\n",
    "'''documents = pdf + text\n",
    "print(\"Total number of documents: \", len(documents))\n",
    "#documents'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 02:06:18,417 [INFO] Note: NumExpr detected 11 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2025-07-10 02:06:18,418 [INFO] NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading: data/pdf/oracle_apkt_hmr_part1_v2.pdf\n",
      "[INFO] Loading: data/pdf/notes_adv_hmr.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 02:06:19,475 [WARNING] Ignoring wrong pointing object 6 0 (offset 0)\n",
      "2025-07-10 02:06:19,475 [WARNING] Ignoring wrong pointing object 9 0 (offset 0)\n",
      "2025-07-10 02:06:19,475 [WARNING] Ignoring wrong pointing object 11 0 (offset 0)\n",
      "2025-07-10 02:06:19,476 [WARNING] Ignoring wrong pointing object 13 0 (offset 0)\n",
      "2025-07-10 02:06:19,476 [WARNING] Ignoring wrong pointing object 16 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading: data/pdf/SBCs_RCSe_lab_HMRs.pdf\n",
      "[INFO] Loading: data/pdf/sip message breakdown.pdf\n",
      "[INFO] Loading: data/pdf/FBNs_HMR_notes.pdf\n",
      "[INFO] Loading: data/pdf/OCC Knowledge Sharing - Regular Expressions 240911.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 02:06:19,798 [WARNING] Ignoring wrong pointing object 6 0 (offset 0)\n",
      "2025-07-10 02:06:19,799 [WARNING] Ignoring wrong pointing object 8 0 (offset 0)\n",
      "2025-07-10 02:06:19,799 [WARNING] Ignoring wrong pointing object 10 0 (offset 0)\n",
      "2025-07-10 02:06:19,800 [WARNING] Ignoring wrong pointing object 12 0 (offset 0)\n",
      "2025-07-10 02:06:19,800 [WARNING] Ignoring wrong pointing object 14 0 (offset 0)\n",
      "2025-07-10 02:06:19,801 [WARNING] Ignoring wrong pointing object 16 0 (offset 0)\n",
      "2025-07-10 02:06:19,801 [WARNING] Ignoring wrong pointing object 18 0 (offset 0)\n",
      "2025-07-10 02:06:19,801 [WARNING] Ignoring wrong pointing object 21 0 (offset 0)\n",
      "2025-07-10 02:06:19,801 [WARNING] Ignoring wrong pointing object 23 0 (offset 0)\n",
      "2025-07-10 02:06:19,802 [WARNING] Ignoring wrong pointing object 29 0 (offset 0)\n",
      "2025-07-10 02:06:19,802 [WARNING] Ignoring wrong pointing object 31 0 (offset 0)\n",
      "2025-07-10 02:06:19,802 [WARNING] Ignoring wrong pointing object 33 0 (offset 0)\n",
      "2025-07-10 02:06:19,803 [WARNING] Ignoring wrong pointing object 38 0 (offset 0)\n",
      "2025-07-10 02:06:19,803 [WARNING] Ignoring wrong pointing object 43 0 (offset 0)\n",
      "2025-07-10 02:06:19,803 [WARNING] Ignoring wrong pointing object 46 0 (offset 0)\n",
      "2025-07-10 02:06:19,804 [WARNING] Ignoring wrong pointing object 49 0 (offset 0)\n",
      "2025-07-10 02:06:19,804 [WARNING] Ignoring wrong pointing object 69 0 (offset 0)\n",
      "2025-07-10 02:06:19,804 [WARNING] Ignoring wrong pointing object 85 0 (offset 0)\n",
      "2025-07-10 02:06:19,805 [WARNING] Ignoring wrong pointing object 87 0 (offset 0)\n",
      "2025-07-10 02:06:19,805 [WARNING] Ignoring wrong pointing object 102 0 (offset 0)\n",
      "2025-07-10 02:06:19,805 [WARNING] Ignoring wrong pointing object 104 0 (offset 0)\n",
      "2025-07-10 02:06:19,805 [WARNING] Ignoring wrong pointing object 106 0 (offset 0)\n",
      "2025-07-10 02:06:19,806 [WARNING] Ignoring wrong pointing object 108 0 (offset 0)\n",
      "2025-07-10 02:06:19,806 [WARNING] Ignoring wrong pointing object 164 0 (offset 0)\n",
      "2025-07-10 02:06:19,808 [WARNING] Ignoring wrong pointing object 312 0 (offset 0)\n",
      "2025-07-10 02:06:19,808 [WARNING] Ignoring wrong pointing object 314 0 (offset 0)\n",
      "2025-07-10 02:06:19,808 [WARNING] Ignoring wrong pointing object 316 0 (offset 0)\n",
      "2025-07-10 02:06:19,808 [WARNING] Ignoring wrong pointing object 318 0 (offset 0)\n",
      "2025-07-10 02:06:19,809 [WARNING] Ignoring wrong pointing object 320 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading: data/pdf/Oracle-SBC-VoLTE-Lab_Config_v0.4.pdf\n",
      "[INFO] Loading: data/pdf/590-0009-01 TECH NOTE HMR Enhancements S-C6.2.0 S-D7.0.0 S-D7.1.0.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 02:06:21,508 [WARNING] Ignoring wrong pointing object 44 0 (offset 0)\n",
      "2025-07-10 02:06:21,508 [WARNING] Ignoring wrong pointing object 46 0 (offset 0)\n",
      "2025-07-10 02:06:21,510 [WARNING] Ignoring wrong pointing object 179 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading: data/pdf/HMRs - Best Practices and Advanced Techniques.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 02:06:21,981 [WARNING] Ignoring wrong pointing object 9 0 (offset 0)\n",
      "2025-07-10 02:06:21,982 [WARNING] Ignoring wrong pointing object 11 0 (offset 0)\n",
      "2025-07-10 02:06:21,982 [WARNING] Ignoring wrong pointing object 13 0 (offset 0)\n",
      "2025-07-10 02:06:21,982 [WARNING] Ignoring wrong pointing object 15 0 (offset 0)\n",
      "2025-07-10 02:06:21,983 [WARNING] Ignoring wrong pointing object 17 0 (offset 0)\n",
      "2025-07-10 02:06:21,983 [WARNING] Ignoring wrong pointing object 19 0 (offset 0)\n",
      "2025-07-10 02:06:21,984 [WARNING] Ignoring wrong pointing object 21 0 (offset 0)\n",
      "2025-07-10 02:06:21,984 [WARNING] Ignoring wrong pointing object 23 0 (offset 0)\n",
      "2025-07-10 02:06:21,984 [WARNING] Ignoring wrong pointing object 26 0 (offset 0)\n",
      "2025-07-10 02:06:21,984 [WARNING] Ignoring wrong pointing object 38 0 (offset 0)\n",
      "2025-07-10 02:06:21,985 [WARNING] Ignoring wrong pointing object 40 0 (offset 0)\n",
      "2025-07-10 02:06:21,985 [WARNING] Ignoring wrong pointing object 46 0 (offset 0)\n",
      "2025-07-10 02:06:21,985 [WARNING] Ignoring wrong pointing object 48 0 (offset 0)\n",
      "2025-07-10 02:06:21,985 [WARNING] Ignoring wrong pointing object 50 0 (offset 0)\n",
      "2025-07-10 02:06:21,986 [WARNING] Ignoring wrong pointing object 52 0 (offset 0)\n",
      "2025-07-10 02:06:21,986 [WARNING] Ignoring wrong pointing object 58 0 (offset 0)\n",
      "2025-07-10 02:06:21,986 [WARNING] Ignoring wrong pointing object 61 0 (offset 0)\n",
      "2025-07-10 02:06:21,987 [WARNING] Ignoring wrong pointing object 63 0 (offset 0)\n",
      "2025-07-10 02:06:21,987 [WARNING] Ignoring wrong pointing object 70 0 (offset 0)\n",
      "2025-07-10 02:06:21,987 [WARNING] Ignoring wrong pointing object 76 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading: data/pdf/DeltaADV_Cx6.3_NewFeaturesLRT_HMR.pdf\n",
      "[INFO] Loading: data/pdf/hmr_guide.pdf\n",
      "\n",
      "[Document 1 Preview]:\n",
      "Copyright © 2013, Oracle and/or its affiliates. All rights reserved. Interconnect  2013 1\n",
      "\n",
      "[Document 2 Preview]:\n",
      "Configuring Header \n",
      "Manipulation Rules: Part 1 \n",
      "Gabo \n",
      "Training Manager EMEA/CALA\n",
      "\n",
      "[Document 3 Preview]:\n",
      "Copyright © 2013, Oracle and/or its affiliates. All rights reserved. Interconnect  2013 3 \n",
      "The following is intended to outline our general product direction. \n",
      "It is intended for information purposes only, and may not be \n",
      "incorporated into any contract. It is not a commitment to deliver \n",
      "any materia\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "\n",
    "\n",
    "path=\"data/pdf\"\n",
    "glob=\"**/*.pdf\"\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    path=\"data/pdf\",            # Replace with your actual folder path\n",
    "    glob=\"**/*.pdf\",            # Recursive match for PDFs\n",
    "    loader_cls=PyPDFLoader      # Use PyPDFLoader for each file\n",
    ")\n",
    "\n",
    "#docs = loader.load()\n",
    "\n",
    "'''# Preview some results\n",
    "for i, doc in enumerate(docs[:3]):\n",
    "    print(f\"\\n[Document {i+1} Preview]:\\n{doc.page_content[:300]}\")'''\n",
    "\n",
    "\n",
    "import os\n",
    "from langchain.schema import Document\n",
    "from pdf2image import convert_from_path\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "folder_path =\"data/pdf\"\n",
    "def hybrid_pdf_loader(doc):\n",
    "    print(f\"[INFO] Loading: {doc}\")\n",
    "    try:\n",
    "        loader = PyPDFLoader(doc)\n",
    "        docs = loader.load()\n",
    "        if all(doc.page_content.strip() == \"\" for doc in docs):\n",
    "            print(f\"[OCR Fallback] Using OCR for: {doc}\")\n",
    "            images = convert_from_path(doc)\n",
    "            ocr_docs = []\n",
    "            for i, image in enumerate(images):\n",
    "                text = pytesseract.image_to_string(image)\n",
    "                ocr_docs.append(Document(page_content=text, metadata={\"page\": i + 1, \"source\": doc}))\n",
    "            return ocr_docs\n",
    "        return docs\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed loading {doc}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Load all PDFs from folder\n",
    "def load_all_pdfs_from_folder(filepath):\n",
    "    all_docs = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            full_path = os.path.join(folder_path, filename)\n",
    "            all_docs.extend(hybrid_pdf_loader(full_path))\n",
    "    return all_docs\n",
    "\n",
    "# Usage\n",
    "pdf = load_all_pdfs_from_folder(\"data/pdf\")  # pdf path\n",
    "\n",
    "# Preview output\n",
    "for i, doc in enumerate(pdf[:3]):\n",
    "    print(f\"\\n[Document {i+1} Preview]:\\n{doc.page_content[:300]}\")\n",
    "\n",
    "documents = pdf + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Total chunks generated: 842\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Copyright © 2013, Oracle and/or its affiliates. All rights reserved. Interconnect  2013 1\n",
      "Configuring Header \n",
      "Manipulation Rules: Part 1 \n",
      "Gabo \n",
      "Training Manager EMEA/CALA\n",
      "Copyright © 2013, Oracle and/or its affiliates. All rights reserved. Interconnect  2013 3 \n",
      "The following is intended to outline o\n",
      "\n",
      "\n",
      "--- Chunk 2 ---\n",
      "The sip-manipulation object \n",
      " Only one sip-manipulation gets applied to a message on inbound, \n",
      "and only one on outbound \n",
      "– sip-manipulations can be called from a session-agent, realm or sip-\n",
      "interface \n",
      "– A session-agent manipulation overrides all others, a realm overrides \n",
      "sip-interface \n",
      "– For a SI\n",
      "\n",
      "\n",
      "--- Chunk 3 ---\n",
      "only if it’s a tel-URI  \n",
      "– Here we will need a \n",
      "comparison-type of \n",
      "pattern-rule to \n",
      "trigger the regular \n",
      "expression \n",
      "specified in the \n",
      "match-value\n",
      "Copyright © 2013, Oracle and/or its affiliates. All rights reserved. Interconnect  2013 20 \n",
      "Example 3: HMR, the real deal \n",
      "Can you figure out what this \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Step 3: Chunking Function\n",
    "def split_documents(documents: list[Document], chunk_size=5000, chunk_overlap=150):\n",
    "    # Combine all page_content fields into one string\n",
    "    full_text = \"\\n\".join([doc.page_content for doc in documents if doc.page_content.strip()])\n",
    "\n",
    "    if not full_text.strip():\n",
    "        print(\"[WARNING] No content found in the documents.\")\n",
    "        return []\n",
    "\n",
    "    # Wrap into a single Document object\n",
    "    combined_doc = [Document(page_content=full_text)]\n",
    "\n",
    "    # Initialize the text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \"]  # Prioritize bigger splits\n",
    "    )\n",
    "\n",
    "    # Split into chunks\n",
    "    chunks = text_splitter.split_documents(combined_doc)\n",
    "    print(f\"[INFO] Total chunks generated: {len(chunks)}\")\n",
    "\n",
    "    # Preview first 3 chunks\n",
    "    for i, chunk in enumerate(chunks[:3]):\n",
    "        print(f\"\\n--- Chunk {i+1} ---\\n{chunk.page_content[:300]}\\n\")\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Step 4: Run the chunking\n",
    "chunks_val = split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 02:06:26,867 [DEBUG] Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "2025-07-10 02:06:27,081 [DEBUG] Creating converter from 7 to 5\n",
      "2025-07-10 02:06:27,081 [DEBUG] Creating converter from 5 to 7\n",
      "2025-07-10 02:06:27,081 [DEBUG] Creating converter from 7 to 5\n",
      "2025-07-10 02:06:27,082 [DEBUG] Creating converter from 5 to 7\n",
      "2025-07-10 02:06:27,792 [INFO] PyTorch version 2.6.0 available.\n",
      "2025-07-10 02:06:27,793 [INFO] TensorFlow version 2.18.0 available.\n",
      "2025-07-10 02:06:28,037 [INFO] Use pytorch device_name: mps\n",
      "2025-07-10 02:06:28,038 [INFO] Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "2025-07-10 02:06:28,039 [DEBUG] Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-07-10 02:06:28,282 [DEBUG] https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/11\" 307 0\n",
      "2025-07-10 02:06:28,300 [DEBUG] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/11\" 200 0\n",
      "2025-07-10 02:06:28,512 [DEBUG] https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/11\" 307 0\n",
      "2025-07-10 02:06:28,524 [DEBUG] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json HTTP/11\" 200 0\n",
      "2025-07-10 02:06:28,739 [DEBUG] https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/11\" 307 0\n",
      "2025-07-10 02:06:28,754 [DEBUG] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md HTTP/11\" 200 0\n",
      "2025-07-10 02:06:28,986 [DEBUG] https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/11\" 307 0\n",
      "2025-07-10 02:06:29,001 [DEBUG] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json HTTP/11\" 200 0\n",
      "2025-07-10 02:06:29,253 [DEBUG] https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/11\" 307 0\n",
      "2025-07-10 02:06:29,274 [DEBUG] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json HTTP/11\" 200 0\n",
      "2025-07-10 02:06:29,507 [DEBUG] https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/11\" 404 0\n",
      "2025-07-10 02:06:29,723 [DEBUG] https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/11\" 307 0\n",
      "2025-07-10 02:06:29,735 [DEBUG] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/11\" 200 0\n",
      "2025-07-10 02:06:30,374 [DEBUG] https://huggingface.co:443 \"HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/11\" 307 0\n",
      "2025-07-10 02:06:30,388 [DEBUG] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/11\" 200 0\n",
      "2025-07-10 02:06:30,610 [DEBUG] https://huggingface.co:443 \"GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/11\" 404 64\n",
      "2025-07-10 02:06:30,906 [DEBUG] https://huggingface.co:443 \"GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/11\" 200 6863\n",
      "2025-07-10 02:06:31,128 [DEBUG] https://huggingface.co:443 \"GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/11\" 200 6863\n",
      "2025-07-10 02:06:31,439 [DEBUG] Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)\n",
      "2025-07-10 02:06:31,441 [INFO] Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Chunks to embed: 842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 02:06:31,480 [DEBUG] Starting component System\n",
      "2025-07-10 02:06:31,480 [DEBUG] Starting component Posthog\n",
      "2025-07-10 02:06:32,000 [DEBUG] Starting new HTTPS connection (1): us.i.posthog.com:443\n",
      "2025-07-10 02:06:32,712 [DEBUG] https://us.i.posthog.com:443 \"POST /batch/ HTTP/11\" 200 15\n",
      "/var/folders/lq/vlly5jb54553hnn1xw3httdw0000gp/T/ipykernel_11439/2200326342.py:18: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vector_db.persist()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'def retrieve_relevant_documents(query, k=3):\\n    \"\"\"\\n    Retrieve the top k most relevant document chunks based on the query.\\n    \"\"\"\\n    docs = vector_db.similarity_search(query, k=k)\\n    \\n    retrieved_texts = [doc.page_content for doc in docs]\\n    return retrieved_texts\\n\\n# Example usage:\\nquery = \"How to modify the SIP header in Oracle SBC?\"\\nretrieved_docs = retrieve_relevant_documents(query)\\n\\nprint(\"Top Retrieved Documents:\")\\nfor idx, doc in enumerate(retrieved_docs):\\n    print(f\"\\nDocument {idx+1}:\")\\n    print(doc)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate Vector Embeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Use a pre-trained sentence embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 2: Ensure chunks are valid Document objects\n",
    "# (Assuming you already have `chunks_val` from your splitter function)\n",
    "print(f\"[INFO] Chunks to embed: {len(chunks_val)}\")\n",
    "\n",
    "\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks_val,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "vector_db.persist()\n",
    "\n",
    "#for testing\n",
    "'''def retrieve_relevant_documents(query, k=3):\n",
    "    \"\"\"\n",
    "    Retrieve the top k most relevant document chunks based on the query.\n",
    "    \"\"\"\n",
    "    docs = vector_db.similarity_search(query, k=k)\n",
    "    \n",
    "    retrieved_texts = [doc.page_content for doc in docs]\n",
    "    return retrieved_texts\n",
    "\n",
    "# Example usage:\n",
    "query = \"How to modify the SIP header in Oracle SBC?\"\n",
    "retrieved_docs = retrieve_relevant_documents(query)\n",
    "\n",
    "print(\"Top Retrieved Documents:\")\n",
    "for idx, doc in enumerate(retrieved_docs):\n",
    "    print(f\"\\nDocument {idx+1}:\")\n",
    "    print(doc)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Perfect till abovesteps,Please refer chatgpt for next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from langchain.embeddings import HuggingFaceEmbeddings\\nfrom langchain.vectorstores import Chroma\\n\\nmodel_name_sent = \"sentence-transformers/all-MiniLM-L6-v2\"\\ntokenizer = AutoTokenizer.from_pretrained(model_name_sent)\\nmodel = AutoModel.from_pretrained(model_name_sent)\\n\\nembedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\\n\\nvector_db = Chroma.from_documents(chunks_val, embedding, persist_directory=\"./chroma_db\")\\nvector_db.persist()'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model directly\n",
    "#from transformers import AutoTokenizer, AutoModel\n",
    "'''import torch\n",
    "import torch.nn.functional as F\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter'''\n",
    "\n",
    "#repaetd above code\n",
    "'''from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "model_name_sent = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_sent)\n",
    "model = AutoModel.from_pretrained(model_name_sent)\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vector_db = Chroma.from_documents(chunks_val, embedding, persist_directory=\"./chroma_db\")\n",
    "vector_db.persist()'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 08:50:30,918 [DEBUG] Resetting dropped connection: huggingface.co\n",
      "2025-07-10 08:50:31,167 [DEBUG] https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B-Instruct-1M/resolve/main/tokenizer_config.json HTTP/11\" 307 0\n",
      "2025-07-10 08:50:31,182 [DEBUG] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/Qwen/Qwen2.5-14B-Instruct-1M/620fad32de7bdd2293b3d99b39eba2fe63e97438/tokenizer_config.json HTTP/11\" 200 0\n",
      "2025-07-10 08:50:31,419 [DEBUG] https://huggingface.co:443 \"GET /api/models/Qwen/Qwen2.5-14B-Instruct-1M/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/11\" 404 64\n",
      "2025-07-10 08:50:31,845 [DEBUG] https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B-Instruct-1M/resolve/main/config.json HTTP/11\" 307 0\n",
      "2025-07-10 08:50:31,861 [DEBUG] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/Qwen/Qwen2.5-14B-Instruct-1M/620fad32de7bdd2293b3d99b39eba2fe63e97438/config.json HTTP/11\" 200 0\n",
      "2025-07-10 08:50:32,097 [DEBUG] https://huggingface.co:443 \"GET /api/models/Qwen/Qwen2.5-14B-Instruct-1M/revision/main HTTP/11\" 200 5560\n",
      "2025-07-10 08:50:32,108 [DEBUG] Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02009f7fba744cd8e361165bf0749ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 08:50:32,108 [DEBUG] Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-07-10 08:50:32,109 [DEBUG] Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-07-10 08:50:32,110 [DEBUG] Resetting dropped connection: huggingface.co\n",
      "2025-07-10 08:50:32,111 [DEBUG] Resetting dropped connection: huggingface.co\n",
      "2025-07-10 08:50:32,111 [DEBUG] Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-07-10 08:50:32,111 [DEBUG] Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-07-10 08:50:32,114 [DEBUG] Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-07-10 08:50:32,363 [DEBUG] https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B-Instruct-1M/resolve/620fad32de7bdd2293b3d99b39eba2fe63e97438/model-00001-of-00008.safetensors HTTP/11\" 302 0\n",
      "2025-07-10 08:50:32,365 [DEBUG] https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B-Instruct-1M/resolve/620fad32de7bdd2293b3d99b39eba2fe63e97438/model-00004-of-00008.safetensors HTTP/11\" 302 0\n",
      "2025-07-10 08:50:32,365 [DEBUG] Attempting to acquire lock 25094896960 on /Users/dishagandhi/.cache/huggingface/hub/.locks/models--Qwen--Qwen2.5-14B-Instruct-1M/3d79fdf7f7675f063904011293255c8129c152ef7e81866a1030d1296dd90324.lock\n",
      "2025-07-10 08:50:32,366 [DEBUG] Attempting to acquire lock 25094712512 on /Users/dishagandhi/.cache/huggingface/hub/.locks/models--Qwen--Qwen2.5-14B-Instruct-1M/38f7f961dced9a2fa403566758f43a5679f5a69becad878029e5a1b482165ff3.lock\n",
      "2025-07-10 08:50:32,367 [DEBUG] Lock 25094896960 acquired on /Users/dishagandhi/.cache/huggingface/hub/.locks/models--Qwen--Qwen2.5-14B-Instruct-1M/3d79fdf7f7675f063904011293255c8129c152ef7e81866a1030d1296dd90324.lock\n",
      "2025-07-10 08:50:32,368 [DEBUG] Lock 25094712512 acquired on /Users/dishagandhi/.cache/huggingface/hub/.locks/models--Qwen--Qwen2.5-14B-Instruct-1M/38f7f961dced9a2fa403566758f43a5679f5a69becad878029e5a1b482165ff3.lock\n",
      "2025-07-10 08:50:32,371 [DEBUG] https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B-Instruct-1M/resolve/620fad32de7bdd2293b3d99b39eba2fe63e97438/model-00002-of-00008.safetensors HTTP/11\" 302 0\n",
      "2025-07-10 08:50:32,372 [DEBUG] Attempting to acquire lock 13675677168 on /Users/dishagandhi/.cache/huggingface/hub/.locks/models--Qwen--Qwen2.5-14B-Instruct-1M/3e3df4d18bc194e09c52e0a1111a85ec4045ace55f1f58a505cfb3688f28a00e.lock\n",
      "2025-07-10 08:50:32,373 [DEBUG] Lock 13675677168 acquired on /Users/dishagandhi/.cache/huggingface/hub/.locks/models--Qwen--Qwen2.5-14B-Instruct-1M/3e3df4d18bc194e09c52e0a1111a85ec4045ace55f1f58a505cfb3688f28a00e.lock\n",
      "2025-07-10 08:50:32,374 [DEBUG] https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B-Instruct-1M/resolve/620fad32de7bdd2293b3d99b39eba2fe63e97438/model-00007-of-00008.safetensors HTTP/11\" 302 0\n",
      "2025-07-10 08:50:32,375 [DEBUG] Attempting to acquire lock 13675622720 on /Users/dishagandhi/.cache/huggingface/hub/.locks/models--Qwen--Qwen2.5-14B-Instruct-1M/9aafbaab860ba050c95b9876156f8ec6c4e1dad658744d11ca6b784ed2e94d3c.lock\n",
      "2025-07-10 08:50:32,376 [DEBUG] Lock 13675622720 acquired on /Users/dishagandhi/.cache/huggingface/hub/.locks/models--Qwen--Qwen2.5-14B-Instruct-1M/9aafbaab860ba050c95b9876156f8ec6c4e1dad658744d11ca6b784ed2e94d3c.lock\n",
      "2025-07-10 08:50:32,383 [DEBUG] https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B-Instruct-1M/resolve/620fad32de7bdd2293b3d99b39eba2fe63e97438/model-00006-of-00008.safetensors HTTP/11\" 302 0\n",
      "2025-07-10 08:50:32,384 [DEBUG] https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B-Instruct-1M/resolve/620fad32de7bdd2293b3d99b39eba2fe63e97438/model-00003-of-00008.safetensors HTTP/11\" 302 0\n",
      "2025-07-10 08:50:32,385 [DEBUG] Attempting to acquire lock 25093992336 on /Users/dishagandhi/.cache/huggingface/hub/.locks/models--Qwen--Qwen2.5-14B-Instruct-1M/03e7f4e1ecdba1385210a6d51c5b75e8878348d47f5f34766710ff20328cc837.lock\n",
      "2025-07-10 08:50:32,386 [DEBUG] https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B-Instruct-1M/resolve/620fad32de7bdd2293b3d99b39eba2fe63e97438/model-00005-of-00008.safetensors HTTP/11\" 302 0\n",
      "2025-07-10 08:50:32,386 [DEBUG] Lock 25093992336 acquired on /Users/dishagandhi/.cache/huggingface/hub/.locks/models--Qwen--Qwen2.5-14B-Instruct-1M/03e7f4e1ecdba1385210a6d51c5b75e8878348d47f5f34766710ff20328cc837.lock\n",
      "2025-07-10 08:50:32,387 [DEBUG] Attempting to acquire lock 25093990800 on /Users/dishagandhi/.cache/huggingface/hub/.locks/models--Qwen--Qwen2.5-14B-Instruct-1M/20721d632a4cb07aa8b66c585ff9cb92ffa517e056e603d60686cd918461760a.lock\n",
      "2025-07-10 08:50:32,388 [DEBUG] Lock 25093990800 acquired on /Users/dishagandhi/.cache/huggingface/hub/.locks/models--Qwen--Qwen2.5-14B-Instruct-1M/20721d632a4cb07aa8b66c585ff9cb92ffa517e056e603d60686cd918461760a.lock\n",
      "2025-07-10 08:50:32,389 [DEBUG] Attempting to acquire lock 25094955200 on /Users/dishagandhi/.cache/huggingface/hub/.locks/models--Qwen--Qwen2.5-14B-Instruct-1M/22450886733306584ecc146502e8c9541ddbf6628474a70f3b3d26c879adc1af.lock\n",
      "2025-07-10 08:50:32,391 [DEBUG] Lock 25094955200 acquired on /Users/dishagandhi/.cache/huggingface/hub/.locks/models--Qwen--Qwen2.5-14B-Instruct-1M/22450886733306584ecc146502e8c9541ddbf6628474a70f3b3d26c879adc1af.lock\n",
      "2025-07-10 08:50:32,396 [DEBUG] https://huggingface.co:443 \"HEAD /Qwen/Qwen2.5-14B-Instruct-1M/resolve/620fad32de7bdd2293b3d99b39eba2fe63e97438/model-00008-of-00008.safetensors HTTP/11\" 302 0\n",
      "2025-07-10 08:50:32,397 [DEBUG] Attempting to acquire lock 13676096608 on /Users/dishagandhi/.cache/huggingface/hub/.locks/models--Qwen--Qwen2.5-14B-Instruct-1M/6a976453176ee8965212c4798fa335f749578f56f864d10905f0963a38afa322.lock\n",
      "2025-07-10 08:50:32,398 [DEBUG] Lock 13676096608 acquired on /Users/dishagandhi/.cache/huggingface/hub/.locks/models--Qwen--Qwen2.5-14B-Instruct-1M/6a976453176ee8965212c4798fa335f749578f56f864d10905f0963a38afa322.lock\n",
      "2025-07-10 08:50:32,599 [DEBUG] https://huggingface.co:443 \"GET /api/models/Qwen/Qwen2.5-14B-Instruct-1M/xet-read-token/620fad32de7bdd2293b3d99b39eba2fe63e97438 HTTP/11\" 200 379\n",
      "2025-07-10 08:50:32,600 [DEBUG] https://huggingface.co:443 \"GET /api/models/Qwen/Qwen2.5-14B-Instruct-1M/xet-read-token/620fad32de7bdd2293b3d99b39eba2fe63e97438 HTTP/11\" 200 379\n",
      "2025-07-10 08:50:32,605 [DEBUG] https://huggingface.co:443 \"GET /api/models/Qwen/Qwen2.5-14B-Instruct-1M/xet-read-token/620fad32de7bdd2293b3d99b39eba2fe63e97438 HTTP/11\" 200 379\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eac86ac52c4408eb8845f89304f256f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 08:50:32,608 [DEBUG] https://huggingface.co:443 \"GET /api/models/Qwen/Qwen2.5-14B-Instruct-1M/xet-read-token/620fad32de7bdd2293b3d99b39eba2fe63e97438 HTTP/11\" 200 379\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fc94cb67c142dd81ded86846660301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00008.safetensors:   0%|          | 0.00/3.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 08:50:32,608 [DEBUG] https://huggingface.co:443 \"GET /api/models/Qwen/Qwen2.5-14B-Instruct-1M/xet-read-token/620fad32de7bdd2293b3d99b39eba2fe63e97438 HTTP/11\" 200 379\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d10880a95004d4aa65e15cb910d2db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00008.safetensors:   0%|          | 0.00/3.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 08:50:32,610 [DEBUG] https://huggingface.co:443 \"GET /api/models/Qwen/Qwen2.5-14B-Instruct-1M/xet-read-token/620fad32de7bdd2293b3d99b39eba2fe63e97438 HTTP/11\" 200 379\n",
      "2025-07-10 08:50:32,625 [DEBUG] https://huggingface.co:443 \"GET /api/models/Qwen/Qwen2.5-14B-Instruct-1M/xet-read-token/620fad32de7bdd2293b3d99b39eba2fe63e97438 HTTP/11\" 200 379\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be5ce5420ab415f9ea7556eabf1154f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 08:50:32,627 [DEBUG] https://huggingface.co:443 \"GET /api/models/Qwen/Qwen2.5-14B-Instruct-1M/xet-read-token/620fad32de7bdd2293b3d99b39eba2fe63e97438 HTTP/11\" 200 379\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfa48fe6ac54ac9a8bb16921260ddf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ad2d7f347142f191fb60c5d1d50e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c920844d084f568cdd514f885515bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f619b7489002428d9505221f0c0ab3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00008.safetensors:   0%|          | 0.00/1.70G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"timestamp\":\"2025-07-10T03:21:05.412530Z\",\"level\":\"WARN\",\"fields\":{\"message\":\"Reqwest(reqwest::Error { kind: Request, url: \\\"https://transfer.xethub.hf.co/xorbs/default/1ff72b075f0f894e9087c0cf6de3e2dfeb2ae701eef4be996360c9ae890e7245?X-Xet-Signed-Range=bytes%3D32900786-58197453&Expires=1752121234&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly90cmFuc2Zlci54ZXRodWIuaGYuY28veG9yYnMvZGVmYXVsdC8xZmY3MmIwNzVmMGY4OTRlOTA4N2MwY2Y2ZGUzZTJkZmViMmFlNzAxZWVmNGJlOTk2MzYwYzlhZTg5MGU3MjQ1P1gtWGV0LVNpZ25lZC1SYW5nZT1ieXRlcyUzRDMyOTAwNzg2LTU4MTk3NDUzIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNzUyMTIxMjM0fX19XX0_&Signature=cI65SZcloW11n5LMtLscA6Zbmuuiw3x4WwiHOpWruHmSdvF1AtcpkbdkeOh6YO1AT3kJNILaSfgjDexhIID0Duc2olIRFEKtN940e09YoBfxKV9HxXtTQ8klmyn2QF4--VH4tDnchbMYjKipvCMOWbHX3vGBYGL59dlQEbx2NfZ0XhADfgj4kExqyafqA3G3Tc7BkCdD8T1IwflOS6B2M5rLepr0fnaTNEhx9lqcS1osxjwn7FROd74fDcSTzxP~vdRX9eZwA~AUct~bwcNP3iJB3jm2sapLXBMWII2IktTEw9619V0XOfyEDdHckNKy5Yi5pv8jCEyj0WsDEvPeNA__&Key-Pair-Id=K2L8F4GPSG1IFC\\\", source: hyper_util::client::legacy::Error(Connect, Error { code: -9805, message: \\\"connection closed gracefully\\\" }) }). Retrying...\"},\"filename\":\"/Users/runner/work/xet-core/xet-core/cas_client/src/http_client.rs\",\"line_number\":200}\n",
      "{\"timestamp\":\"2025-07-10T03:21:05.412751Z\",\"level\":\"WARN\",\"fields\":{\"message\":\"Retry attempt #0. Sleeping 236.372435ms before the next attempt\"},\"filename\":\"/Users/runner/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs\",\"line_number\":171}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM,BitsAndBytesConfig\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-14B-Instruct-1M\" #\"mistralai/Mistral-7B-Instruct-v0.3\" \n",
    "'''quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_quant_type=\"nf4\" \n",
    "    \n",
    ")'''\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id,token=\"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\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\",token=\"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\")\n",
    "\n",
    "llm_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=200,temperature=0.1, repetition_penalty=1.2)\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "\n",
    "retriever = vector_db.as_retriever(earch_kwargs={\"k\": 5}, search_type=\"similarity\", search_score_threshold=0.5)\n",
    "rag_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)\n",
    "\n",
    "'''def get_hmr_response(user_input):\n",
    "    response = rag_chain.run(user_input)\n",
    "    return response'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#looks OK till here tesing from next ssteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "  \n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"intent\": \"Add P-Asserted-Identity using From header\",\n",
    "        \"sip_msg\": \"INVITE sip:bob@oracle.com SIP/2.0\\nFrom: <sip:alice@telco.com>\",\n",
    "        \"hmr\": \"\"\"\n",
    "header-rule\n",
    "  name                                    addPAI\n",
    "  header-name                             p-asserted-identity\n",
    "  action                                  add\n",
    "  comparison-type                         pattern-rule\n",
    "  msg-type                                request\n",
    "  methods                                 INVITE\n",
    "  new-value                               \"<sip:\"+$From.$From_er.$0+\"@telco.com>\"\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"intent\": \"Remove Diversion Header\",\n",
    "        \"sip_msg\": \"INVITE sip:bob@oracle.com SIP/2.0\\nDiversion: <sip:olduser@domain.com>\",\n",
    "        \"hmr\": \"\"\"\n",
    "header-rule\n",
    "  name                                    removeDiversion\n",
    "  header-name                             diversion\n",
    "  action                                  remove\n",
    "  comparison-type                         pattern-rule\n",
    "  msg-type                                request\n",
    "  methods                                 INVITE\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"intent\": \"Replace domain in From header to newdomain.com\",\n",
    "        \"sip_msg\": \"From: <sip:user@olddomain.com>\",\n",
    "        \"hmr\": \"\"\"\n",
    "header-rule\n",
    "  name                                    replaceFromDomain\n",
    "  header-name                             from\n",
    "  action                                  replace\n",
    "  comparison-type                         pattern-rule\n",
    "  msg-type                                request\n",
    "  methods                                 INVITE\n",
    "  match-value                             \"olddomain.com\"\n",
    "  new-value                               \"newdomain.com\"\n",
    "\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"intent\", \"sip_msg\", \"hmr\"],\n",
    "    template=\"\"\"\n",
    "Intent: {intent}\n",
    "\n",
    "SIP Message:\n",
    "{sip_msg}\n",
    "\n",
    "HMR:\n",
    "{hmr}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "hmr_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"\"\"\n",
    ".You are an expert in Oracle SBC Header Manipulation Rules (HMR).Given the user intent and SIP message,Output ONLY in Oracle SBC HMR CLI format.\n",
    "\"\"\",\n",
    "    suffix=\"\"\"\n",
    "Intent: {intent}\n",
    "SIP Message:\n",
    "{sip_msg}\n",
    "\n",
    "HMR:\n",
    "\"\"\",\n",
    "    input_variables=[\"intent\", \"sip_msg\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "'''def load_llm():\n",
    "    model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", torch_dtype=\"auto\")\n",
    "    pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512)\n",
    "    return HuggingFacePipeline(pipeline=pipe)'''\n",
    "\n",
    "# mod this and remove duplicate and vode as above declare it \n",
    "def get_hmr_response(intent, sip_msg,llm):\n",
    "    #retriever = vectordb.as_retriever(search_kwargs={\"k\": 4})\n",
    "    relevant_docs = retriever.get_relevant_documents(f\"{intent}\\n{sip_msg}\")\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in relevant_docs)\n",
    "\n",
    "    prompt = hmr_prompt_template.format(intent=intent, sip_msg=sip_msg, context=context)\n",
    "    #llm = llm\n",
    "    response = llm(prompt)\n",
    "    \n",
    "    # Clean and return ONLY CLI block\n",
    "    if isinstance(response, list):\n",
    "        return response[0]['generated_text'].strip()\n",
    "    elif isinstance(response, str):\n",
    "        return response.strip()\n",
    "    return str(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 02:10:10,729 [INFO] Disabled Gradio telemetry\n",
      "2025-07-10 02:10:10,730 [INFO] Cleared torch memory cache\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "for var in ['MallocStackLogging', 'MallocStackLoggingLite']:\n",
    "    if var in os.environ:\n",
    "        del os.environ[var]\n",
    "os.environ[\"GRADIO_ANALYTICS_ENABLED\"] = \"False\"\n",
    "logger.info(\"Disabled Gradio telemetry\")\n",
    "torch.cuda.empty_cache()\n",
    "torch.mps.empty_cache()\n",
    "logger.info(\"Cleared torch memory cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"cyan\", secondary_hue=\"gray\")) as demo:\n",
    "    with gr.Column():\n",
    "        intent_input = gr.Textbox(label=\"Intent / Requirement\", lines=2, placeholder=\"e.g., Add P-Asserted-Identity using From header\")\n",
    "        sip_msg_input = gr.Textbox(label=\"SIP Message\", lines=10, placeholder=\"e.g., INVITE sip:bob@oracle.com SIP/2.0\\nFrom: <sip:alice@telco.com>\")\n",
    "        output = gr.Textbox(label=\"Oracle SBC HMR CLI Output\", lines=15, interactive=False)\n",
    "        submit_btn = gr.Button(\"Generate HMR\", variant=\"primary\")\n",
    "\n",
    "        # Bind the function with the llm object\n",
    "        submit_btn.click(\n",
    "            fn=lambda intent, sip_msg: get_hmr_response(intent, sip_msg, llm),  # Pass llm explicitly\n",
    "            inputs=[intent_input, sip_msg_input],\n",
    "            outputs=output\n",
    "        )\n",
    "        \n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<string>:22\u001b[0;36m\u001b[0m\n\u001b[0;31m    gr.Button.click(\"Connect to SBC\", variant=\"secondary\", elem_id=\"connect_sbc_btn\",min_width=150,inputs=[ip_addr, passwrd])\u001b[0m\n\u001b[0m                                                                                                                             ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#new please change the code for frontend correctly---Disha  prefer\n",
    "#import gradio as gr\n",
    "\n",
    "\n",
    "'''def generate_hmr_cli(intent, sip_msg):\n",
    "    #return get_hmr_response(intent, sip_msg, vector_db)'''\n",
    "\n",
    "'''\n",
    "with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"cyan\", secondary_hue=\"gray\")) as demo:\n",
    "    with gr.Column():\n",
    "        iface = gr.Interface(\n",
    "        fn=get_hmr_response,\n",
    "        inputs=[gr.Textbox(label=\"Intent / Requirement\",lines=2), gr.Textbox(label=\"SIP Message\",lines=10)],\n",
    "        outputs=gr.Textbox(label=\"Oracle SBC HMR CLI Output\",lines=15),\n",
    "        title=\"Oracle SBC HMR Generator and Testing Tool\",submit_btn=\"Generate HMR\",flagging_mode=\"never\",theme=gr.themes.Ocean()\n",
    "        )\n",
    "        \n",
    "        #testing tool could be comments for LLM REVIEW\n",
    "    with gr.Column():\n",
    "        #gr.Markdown(\"=====================================================================================================================================================================================\")\n",
    "        with gr.Row():\n",
    "            ip_addr = gr.Textbox(label=\"IP address of SBC\", value=\"\")\n",
    "            passwrd = gr.Textbox(label=\"SBC admin Password\", type=\"password\")\n",
    "        gr.Button.click(\"Connect to SBC\", variant=\"secondary\", elem_id=\"connect_sbc_btn\",min_width=150,inputs=[ip_addr, passwrd])\n",
    "        gr.Textbox(label=\"SBC HMR Testing Output\", lines=15, placeholder=\"Output will be displayed here after testing HMR on SBC\")\n",
    "demo.launch(share=True)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#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\n",
    "# Set your Hugging Face token (keep it secret!)\n",
    "os.environ[\"HUGGINGFACE_TOKEN\"] = \"HF_Mistral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "/var/folders/lq/vlly5jb54553hnn1xw3httdw0000gp/T/ipykernel_10329/2191869267.py:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  '''import paramiko\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'import paramiko\\nfrom paramiko_expect import SSHClientInteraction\\n\\nprompt = r\\'\\\\S*#\\\\s*\\'\\ndef connect_to_sbc(ip, password):\\n        # Create an SSH client\\n        ip = str(input(\"Enter the IP address of the SBC: \"))\\n        password = str(input(\"Enter the SBC admin password: \"))\\n        client = paramiko.SSHClient()\\n        client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\\n        \\n        # Connect to the SBC\\n        client.connect(ip, username=\\'admin\\', password=password)\\n        \\n        \\n        # Use SSHClientInteraction for interactive commands\\n        interaction = SSHClientInteraction(hostname=ip, port=22, username=\"admin\", password=password)\\n        output = interaction.expect(prompt)\\n\\n        output = \"\"\\n\\n        with open(\\'test-manip.rtf\\') as f:\\n            lines = f.readlines()\\n            for command in lines:\\n                interaction.send(command)\\n        client.close()\\n\\n        #return output'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 01:16:13,083 [DEBUG] https://huggingface.co:443 \"HEAD /api/telemetry/gradio/launched HTTP/11\" 200 0\n"
     ]
    }
   ],
   "source": [
    "#code for testing via sbc login\n",
    "'''import paramiko\n",
    "from paramiko_expect import SSHClientInteraction\n",
    "\n",
    "prompt = r'\\S*#\\s*'\n",
    "def connect_to_sbc(ip, password):\n",
    "        # Create an SSH client\n",
    "        ip = str(input(\"Enter the IP address of the SBC: \"))\n",
    "        password = str(input(\"Enter the SBC admin password: \"))\n",
    "        client = paramiko.SSHClient()\n",
    "        client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "        \n",
    "        # Connect to the SBC\n",
    "        client.connect(ip, username='admin', password=password)\n",
    "        \n",
    "        \n",
    "        # Use SSHClientInteraction for interactive commands\n",
    "        interaction = SSHClientInteraction(hostname=ip, port=22, username=\"admin\", password=password)\n",
    "        output = interaction.expect(prompt)\n",
    "\n",
    "        output = \"\"\n",
    "\n",
    "        with open('test-manip.rtf') as f:\n",
    "            lines = f.readlines()\n",
    "            for command in lines:\n",
    "                interaction.send(command)\n",
    "        client.close()\n",
    "\n",
    "        #return output'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
